#!/usr/bin/env python
# Add notes to readme
# brew install enchant
# GL windows, maybe a docker container?
# export PYENCHANT_LIBRARY_PATH=/opt/homebrew/lib/libenchant-2.dylib

import argparse
import datetime
import os
from string import punctuation

import enchant
import nltk
from emoji import emojize, is_emoji
from nltk.corpus import stopwords

from utils import encode_string, get_data_to_parse, initial_file_load, write_to_file

d = enchant.Dict("en_GB")
nltk.download("wordnet")
nltk.download("stopwords")
stop_words = set(stopwords.words("english"))

invalid_words = []
SAVE_INVALID_WORDS = False
REFERRAL_LINKS = ["share.octopus.energy", "trading212.com/invite", "join.monzo.com"]


def verified_word(word):
    # Check for http in word
    if "http" in word:
        invalid_words.append(word)
        return None
    # Check if the word is numeric
    if word.isnumeric():
        invalid_words.append(word)
        return None
    # Check if the word is an emoji
    if is_emoji(emojize(word)):
        invalid_words.append(word)
        return None

    # Check if the word without punctuation still has a value
    if len(word.strip(punctuation)) > 0:
        # Check if the word is valid according to pyenchant
        if not d.check(word.strip(punctuation)):
            invalid_words.append(word)
            return None
    cleaned_word = "".join(
        e for e in encode_string(string=word, emojize=True) if e.isalnum()
    )
    if cleaned_word not in stop_words:
        return cleaned_word


def emoji_or_noji(word, emojis_only):
    if word is None:
        return False
    if emojis_only is not True:
        return True
    if is_emoji(emojize(word)):
        return True
    return False


def list_every_word(all_messages, emojis_only):
    all_words = set()
    for message in all_messages:
        try:
            content = message.get("content", "")
            words = content.split(" ")

            for word in words:
                formatted_word = verified_word(word)
                if emoji_or_noji(formatted_word, emojis_only):
                    all_words.add(formatted_word)
        except KeyError:
            continue

    return list(all_words)


def main(
    *,
    data_to_parse,
    date_range_start,
    date_range_end,
    emojis_only,
    capture_context,
    compare_year,
):
    all_previous_years_words = set()

    if compare_year:
        today = datetime.now()
        messages, _ = get_data_to_parse(
            data_to_parse, "-".join([str(today.year), "01"]), None
        )
        all_messages, _ = get_data_to_parse(
            data_to_parse,
            None,
            "-".join([str(today.year - 1), "12"]),
        )
        all_previous_years_words = list_every_word(all_messages, emojis_only)

    else:
        messages, _ = get_data_to_parse(data_to_parse, date_range_start, date_range_end)

    word_data = {}
    sender_count = {}

    messages.reverse()
    for message in messages:
        try:
            words = message.get("content", "").lower().split(" ")
            sender_name = message.get("sender_name", "")
            for word in words:
                formatted_word = verified_word(word)
                if (
                    emoji_or_noji(formatted_word, emojis_only)
                    and formatted_word not in all_previous_years_words
                ):
                    if formatted_word in word_data.keys():
                        word_data[formatted_word]["count"] += 1
                    else:
                        word_data[formatted_word] = {
                            "count": 1,
                            "op": sender_name,
                        }

                        if capture_context:
                            word_data[formatted_word]["context"] = message.get(
                                "content", ""
                            )
                        sender_count[sender_name] = sender_count.get(sender_name, 0) + 1

        except KeyError:
            continue

    sorted_word_data = dict(
        sorted(word_data.items(), key=lambda item: item[1]["count"], reverse=True)
    )
    sorted_sender_count = dict(sorted(sender_count.items(), key=lambda item: item[1]))

    sorted_word_data["sender_count"] = sorted_sender_count
    if SAVE_INVALID_WORDS:
        sorted_word_data["invalid_words"] = sorted(list(dict.fromkeys(invalid_words)))

    longest_message = {"content": ""}
    for message in messages:
        # if sender_name == message.get("sender_name"):
        #     print(message.get("content", message), message.get("sender_name"))
        #     sender_chain += 1
        #     sorted_word_data["longest_chain_of_messages"] = {sender_name: sender_chain}
        # else:
        #     sender_chain = 0
        sender_name = message.get("sender_name")

        if any(link in message.get("content", "") for link in REFERRAL_LINKS):
            if not sorted_word_data.get("referer_count"):
                sorted_word_data["referer_count"] = {}
            sender_count = sorted_word_data["referer_count"].get(sender_name, 0)
            sorted_word_data["referer_count"][sender_name] = sender_count + 1

        if len(message.get("content", "").split(" ")) > len(
            longest_message.get("content").split(" ")
        ):
            longest_message = message
            longest_message["word_count"] = len(message.get("content").split(" "))
            sorted_word_data["longest_message"] = longest_message

    write_to_file(file_name="unique_words.json", data=sorted_word_data)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-f", "--file", type=str, required=True)
    parser.add_argument("--multichat", type=bool, default=False)
    parser.add_argument(
        "--drstart",
        type=str,
        help="The date range start for getting messages, format needs to be (YYYY-MM)",
    )
    parser.add_argument(
        "--drend",
        type=str,
        help="The date range end for getting messages, format needs to be (YYYY-MM)",
    )
    parser.add_argument(
        "--emojis", type=bool, default=False, help="Only count emojis rather than words"
    )
    parser.add_argument(
        "--context", type=bool, default=False, help="Save the context of the word"
    )
    parser.add_argument(
        "--compareyear",
        type=bool,
        default=False,
        help="Compare the current year to the previous years",
    )

    args = parser.parse_args()
    if os.path.exists(args.file):
        main(
            data_to_parse=initial_file_load(args.file, args.multichat),
            date_range_start=args.drstart,
            date_range_end=args.drend,
            emojis_only=args.emojis,
            capture_context=args.context,
            compare_year=args.compareyear,
        )
